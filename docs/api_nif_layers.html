
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>nif.layers &#8212; NIF  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/classic.css" />
    
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="nif.model" href="api_nif_model.html" />
    <link rel="prev" title="nif.optimizers" href="api_nif_optimizers.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="api_nif_model.html" title="nif.model"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="api_nif_optimizers.html" title="nif.optimizers"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">NIF  documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">nif.layers</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="module-nif.layers">
<span id="nif-layers"></span><h1>nif.layers<a class="headerlink" href="#module-nif.layers" title="Permalink to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="nif.layers.SIREN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nif.layers.</span></span><span class="sig-name descname"><span class="pre">SIREN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.SIREN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">PrunableLayer</span></code></p>
<p>A class representing the SIREN layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_inputs</strong> (<em>int</em>) – The number of input units.</p></li>
<li><p><strong>num_outputs</strong> (<em>int</em>) – The number of output units.</p></li>
<li><p><strong>layer_position</strong> (<em>str</em>) – The position of the SIREN layer in the network architecture.
Possible values are ‘first’, ‘hidden’, ‘last’ and ‘bottleneck’.</p></li>
<li><p><strong>omega_0</strong> (<em>float</em>) – The cutoff frequency for the initial frequency. Should be set to 1.0
for most cases.</p></li>
<li><p><strong>cfg_shape_net</strong> (<em>dict</em>) – A dictionary containing the configuration parameters for the network
if the layer position is ‘last’.</p></li>
<li><p><strong>kernel_regularizer</strong> (<em>tf.keras.regularizers.Regularizer</em>) – Regularizer function applied to
the kernel weights matrix.</p></li>
<li><p><strong>bias_regularizer</strong> (<em>tf.keras.regularizers.Regularizer</em>) – Regularizer function applied to the
bias vector.</p></li>
<li><p><strong>mixed_policy</strong> (<em>tf.keras.mixed_precision.Policy</em>) – A mixed precision policy used for the
weights and biases.</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Variables<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>w_init</strong> (<em>tf.Tensor</em>) – The initialized weights.</p></li>
<li><p><strong>b_init</strong> (<em>tf.Tensor</em>) – The initialized biases.</p></li>
<li><p><strong>w</strong> (<em>tf.Variable</em>) – The learnable weights.</p></li>
<li><p><strong>b</strong> (<em>tf.Variable</em>) – The learnable biases.</p></li>
<li><p><strong>compute_Dtype</strong> (<em>tf.DType</em>) – The computational datatype of the layer.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.SIREN.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.SIREN.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.SIREN.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.SIREN.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.SIREN.get_prunable_weights">
<span class="sig-name descname"><span class="pre">get_prunable_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.SIREN.get_prunable_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the prunable weights of the layer.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id0">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#id0" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the output of the layer given an input tensor x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>tf.Tensor</em>) – Input tensor of shape (batch_size, input_dim).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>tf.Tensor</em> – Output tensor of shape (batch_size, output_dim).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id1">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#id1" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the configuration of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>dict</em> – The configuration of the layer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id2">
<span class="sig-name descname"><span class="pre">get_prunable_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#id2" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the list of prunable weights of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>list</em> – The list of prunable weights of the layer.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nif.layers.SIREN_ResNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nif.layers.</span></span><span class="sig-name descname"><span class="pre">SIREN_ResNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.SIREN_ResNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nif.layers.SIREN" title="nif.layers.siren.SIREN"><code class="xref py py-class docutils literal notranslate"><span class="pre">SIREN</span></code></a></p>
<p>A subclass of the SIREN class implementing a residual block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_inputs</strong> (<em>int</em>) – Number of input features.</p></li>
<li><p><strong>num_outputs</strong> (<em>int</em>) – Number of output features.</p></li>
<li><p><strong>omega_0</strong> (<em>float</em>) – Frequency parameter for the SIREN activation function.</p></li>
<li><p><strong>kernel_regularizer</strong> (<em>tf.keras.regularizers.Regularizer</em>) – Regularizer function
applied to the layer’s weights.</p></li>
<li><p><strong>bias_regularizer</strong> (<em>tf.keras.regularizers.Regularizer</em>) – Regularizer function
applied to the layer’s biases.</p></li>
<li><p><strong>mixed_policy</strong> (<em>tf.keras.mixed_precision.Policy</em>) – Policy to use for mixed
precision computation. Defaults to “float32”.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the parent class constructor.</p></li>
</ul>
</dd>
<dt class="field-even">Variables<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>w2</strong> (<em>tf.Variable</em>) – Weight variable for the second layer of the residual block.</p></li>
<li><p><strong>b2</strong> (<em>tf.Variable</em>) – Bias variable for the second layer of the residual block.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.SIREN_ResNet.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.SIREN_ResNet.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a forward pass through the layer.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.SIREN_ResNet.get_prunable_weights">
<span class="sig-name descname"><span class="pre">get_prunable_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.SIREN_ResNet.get_prunable_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a list of prunable weight variables.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id3">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#id3" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a forward pass through the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>tf.Tensor</em>) – Input tensor.</p></li>
<li><p><strong>training</strong> (<em>bool</em>) – Whether the layer is in training mode.</p></li>
<li><p><strong>mask</strong> – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor of the layer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id4">
<span class="sig-name descname"><span class="pre">get_prunable_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#id4" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Returns the list of prunable weights in the layer, i.e., the weights that can be</dt><dd><p>pruned during training.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of <cite>tf.Variable</cite> objects representing the prunable weights in the layer.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nif.layers.Dense">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nif.layers.</span></span><span class="sig-name descname"><span class="pre">Dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.Dense" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Just your regular densely-connected NN layer.</p>
<p><cite>Dense</cite> implements the operation:
<cite>output = activation(dot(input, kernel) + bias)</cite>
where <cite>activation</cite> is the element-wise activation function
passed as the <cite>activation</cite> argument, <cite>kernel</cite> is a weights matrix
created by the layer, and <cite>bias</cite> is a bias vector created by the layer
(only applicable if <cite>use_bias</cite> is <cite>True</cite>). These are all attributes of
<cite>Dense</cite>.</p>
<p>Note: If the input to the layer has a rank greater than 2, then <cite>Dense</cite>
computes the dot product between the <cite>inputs</cite> and the <cite>kernel</cite> along the
last axis of the <cite>inputs</cite> and axis 0 of the <cite>kernel</cite> (using <cite>tf.tensordot</cite>).
For example, if input has dimensions <cite>(batch_size, d0, d1)</cite>, then we create
a <cite>kernel</cite> with shape <cite>(d1, units)</cite>, and the <cite>kernel</cite> operates along axis 2
of the <cite>input</cite>, on every sub-tensor of shape <cite>(1, 1, d1)</cite> (there are
<cite>batch_size * d0</cite> such sub-tensors).  The output in this case will have
shape <cite>(batch_size, d0, units)</cite>.</p>
<p>Besides, layer attributes cannot be modified after the layer has been called
once (except the <cite>trainable</cite> attribute).
When a popular kwarg <cite>input_shape</cite> is passed, then keras will create
an input layer to insert before the current layer. This can be treated
equivalent to explicitly defining an <cite>InputLayer</cite>.</p>
<p>Example:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create a `Sequential` model and add a Dense layer as the first layer.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Now the model will take as input arrays of shape (None, 16)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and output arrays of shape (None, 32).</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Note that after the first layer, you don&#39;t need to specify</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># the size of the input anymore:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">output_shape</span>
<span class="go">(None, 32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>units</strong> – Positive integer, dimensionality of the output space.</p></li>
<li><p><strong>activation</strong> – Activation function to use.
If you don’t specify anything, no activation is applied
(ie. “linear” activation: <cite>a(x) = x</cite>).</p></li>
<li><p><strong>use_bias</strong> – Boolean, whether the layer uses a bias vector.</p></li>
<li><p><strong>kernel_initializer</strong> – Initializer for the <cite>kernel</cite> weights matrix.</p></li>
<li><p><strong>bias_initializer</strong> – Initializer for the bias vector.</p></li>
<li><p><strong>kernel_regularizer</strong> – Regularizer function applied to
the <cite>kernel</cite> weights matrix.</p></li>
<li><p><strong>bias_regularizer</strong> – Regularizer function applied to the bias vector.</p></li>
<li><p><strong>activity_regularizer</strong> – Regularizer function applied to
the output of the layer (its “activation”).</p></li>
<li><p><strong>kernel_constraint</strong> – Constraint function applied to
the <cite>kernel</cite> weights matrix.</p></li>
<li><p><strong>bias_constraint</strong> – Constraint function applied to the bias vector.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Input shape:</dt><dd><p>N-D tensor with shape: <cite>(batch_size, …, input_dim)</cite>.
The most common situation would be
a 2D input with shape <cite>(batch_size, input_dim)</cite>.</p>
</dd>
<dt>Output shape:</dt><dd><p>N-D tensor with shape: <cite>(batch_size, …, units)</cite>.
For instance, for a 2D input with shape <cite>(batch_size, input_dim)</cite>,
the output would have shape <cite>(batch_size, units)</cite>.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.Dense.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.Dense.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call. It is invoked automatically before
the first execution of <cite>call()</cite>.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses
(at the discretion of the subclass implementer).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.Dense.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.Dense.call" title="Permalink to this definition">¶</a></dt>
<dd><p>This is where the layer’s logic lives.</p>
<p>The <cite>call()</cite> method may not create state (except in its first
invocation, wrapping the creation of variables or other resources in
<cite>tf.init_scope()</cite>).  It is recommended to create state in <cite>__init__()</cite>,
or the <cite>build()</cite> method that is called automatically before <cite>call()</cite>
executes the first time.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul>
<li><p><strong>inputs</strong> – Input tensor, or dict/list/tuple of input tensors.
The first positional <cite>inputs</cite> argument is subject to special rules:
- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>
<blockquote>
<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value
of a keyword argument.</p>
</div></blockquote>
<ul class="simple">
<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as
tensors.</p></li>
<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>
<li><p>Layers are built (<cite>build(input_shape)</cite> method)
using shape info from <cite>inputs</cite> only.</p></li>
<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>
<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.
If a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their
casting behavior in mixed precision should be handled manually.</p></li>
<li><p>The SavedModel input specification is generated using <cite>inputs</cite>
only.</p></li>
<li><p>Integration with various ecosystem packages like TFMOT, TFLite,
TF.js, etc is only supported for <cite>inputs</cite> and not for tensors in
positional and keyword arguments.</p></li>
</ul>
</li>
<li><p><strong>*args</strong> – Additional positional arguments. May contain tensors, although
this is not recommended, for the reasons above.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments. May contain tensors, although
this is not recommended, for the reasons above.
The following optional keyword arguments are reserved:
- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>
<blockquote>
<div><p>whether the <cite>call</cite> is meant for training or inference.</p>
</div></blockquote>
<ul class="simple">
<li><p><cite>mask</cite>: Boolean input mask. If the layer’s <cite>call()</cite> method takes a
<cite>mask</cite> argument, its default value will be set to the mask
generated for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come
from a layer that generated a corresponding mask, i.e. if it came
from a Keras layer with masking support).</p></li>
</ul>
</li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor or list/tuple of tensors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.Dense.compute_output_shape">
<span class="sig-name descname"><span class="pre">compute_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.Dense.compute_output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the output shape of the layer.</p>
<p>This method will cause the layer’s state to be built, if that has not
happened before. This requires that the layer will later be used with
inputs that match the input shape provided here.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Shape tuple (tuple of integers)
or list of shape tuples (one per output tensor of the layer).
Shape tuples can include None for free dimensions,
instead of an integer.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An input shape tuple.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.Dense.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.Dense.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<p>Note that <cite>get_config()</cite> does not guarantee to return a fresh copy of
dict every time it is called. The callers should make a copy of the
returned dict if they want to modify it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nif.layers.HyperLinearForSIREN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nif.layers.</span></span><span class="sig-name descname"><span class="pre">HyperLinearForSIREN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.HyperLinearForSIREN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">PrunableLayer</span></code></p>
<p>Implements a hypernetwork that generates weights and biases for the SIREN layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_inputs</strong> (<em>int</em>) – Number of input units.</p></li>
<li><p><strong>num_outputs</strong> (<em>int</em>) – Number of output units.</p></li>
<li><p><strong>cfg_shape_net</strong> (<em>dict</em>) – Configuration dictionary of the shape network.</p></li>
<li><p><strong>mixed_policy</strong> (<em>tf.keras.mixed_precision.Policy</em>) – Policy for mixed precision computation.</p></li>
<li><p><strong>connectivity</strong> (<em>str</em>) – Connectivity type of the SIREN layer. Should be set to <cite>full</cite> or <cite>last_layer</cite>.</p></li>
<li><p><strong>kernel_regularizer</strong> (<em>tf.keras.regularizers.Regularizer</em>) – Regularizer for the kernel.</p></li>
<li><p><strong>bias_regularizer</strong> (<em>tf.keras.regularizers.Regularizer</em>) – Regularizer for the bias.</p></li>
<li><p><strong>activity_regularizer</strong> (<em>tf.keras.regularizers.Regularizer</em>) – Regularizer for the layer activity.</p></li>
<li><p><strong>**kwargs</strong> – Additional layer arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Variables<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>kernel_regularizer</strong> (<em>tf.keras.regularizers.Regularizer</em>) – Regularizer for the kernel.</p></li>
<li><p><strong>bias_regularizer</strong> (<em>tf.keras.regularizers.Regularizer</em>) – Regularizer for the bias.</p></li>
<li><p><strong>compute_Dtype</strong> (<em>tf.dtypes.DType</em>) – Data type for computation.</p></li>
<li><p><strong>w</strong> (<em>tf.Variable</em>) – Variable for the weights.</p></li>
<li><p><strong>b</strong> (<em>tf.Variable</em>) – Variable for the biases.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.HyperLinearForSIREN.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.HyperLinearForSIREN.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the output of the layer for the input <cite>x</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.HyperLinearForSIREN.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.HyperLinearForSIREN.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the configuration dictionary of the layer.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.HyperLinearForSIREN.get_prunable_weights">
<span class="sig-name descname"><span class="pre">get_prunable_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.HyperLinearForSIREN.get_prunable_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the prunable weights of the layer.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id5">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#id5" title="Permalink to this definition">¶</a></dt>
<dd><p>This is where the layer’s logic lives.</p>
<p>The <cite>call()</cite> method may not create state (except in its first
invocation, wrapping the creation of variables or other resources in
<cite>tf.init_scope()</cite>).  It is recommended to create state in <cite>__init__()</cite>,
or the <cite>build()</cite> method that is called automatically before <cite>call()</cite>
executes the first time.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul>
<li><p><strong>inputs</strong> – Input tensor, or dict/list/tuple of input tensors.
The first positional <cite>inputs</cite> argument is subject to special rules:
- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>
<blockquote>
<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value
of a keyword argument.</p>
</div></blockquote>
<ul class="simple">
<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as
tensors.</p></li>
<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>
<li><p>Layers are built (<cite>build(input_shape)</cite> method)
using shape info from <cite>inputs</cite> only.</p></li>
<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>
<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.
If a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their
casting behavior in mixed precision should be handled manually.</p></li>
<li><p>The SavedModel input specification is generated using <cite>inputs</cite>
only.</p></li>
<li><p>Integration with various ecosystem packages like TFMOT, TFLite,
TF.js, etc is only supported for <cite>inputs</cite> and not for tensors in
positional and keyword arguments.</p></li>
</ul>
</li>
<li><p><strong>*args</strong> – Additional positional arguments. May contain tensors, although
this is not recommended, for the reasons above.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments. May contain tensors, although
this is not recommended, for the reasons above.
The following optional keyword arguments are reserved:
- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>
<blockquote>
<div><p>whether the <cite>call</cite> is meant for training or inference.</p>
</div></blockquote>
<ul class="simple">
<li><p><cite>mask</cite>: Boolean input mask. If the layer’s <cite>call()</cite> method takes a
<cite>mask</cite> argument, its default value will be set to the mask
generated for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come
from a layer that generated a corresponding mask, i.e. if it came
from a Keras layer with masking support).</p></li>
</ul>
</li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor or list/tuple of tensors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id6">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#id6" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<p>Note that <cite>get_config()</cite> does not guarantee to return a fresh copy of
dict every time it is called. The callers should make a copy of the
returned dict if they want to modify it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id7">
<span class="sig-name descname"><span class="pre">get_prunable_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#id7" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns list of prunable weight tensors.</p>
<p>All the weight tensors which the layer wants to be pruned during
training must be returned by this method.</p>
<dl class="simple">
<dt>Returns: List of weight tensors/kernels in the keras layer which must be</dt><dd><p>pruned during training.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nif.layers.MLP_ResNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nif.layers.</span></span><span class="sig-name descname"><span class="pre">MLP_ResNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.MLP_ResNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">PrunableLayer</span></code></p>
<p>A fully connected neural network with residual connections.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>compute_Dtype</strong> (<em>tf.dtypes.DType</em>) – The floating-point precision used for computation.</p></li>
<li><p><strong>variable_Dtype</strong> (<em>tf.dtypes.DType</em>) – The floating-point precision used for variables.</p></li>
<li><p><strong>act</strong> (<em>function</em>) – The activation function to use.</p></li>
<li><p><strong>L1</strong> (<em>tf.keras.layers.Dense</em>) – The first fully connected layer.</p></li>
<li><p><strong>L2</strong> (<em>tf.keras.layers.Dense</em>) – The second fully connected layer.</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>width</strong> (<em>int</em>) – The width of the fully connected layers.</p></li>
<li><p><strong>activation</strong> (<em>str</em>) – The name of the activation function to use.</p></li>
<li><p><strong>kernel_initializer</strong> (<em>str</em>) – The name of the initializer to use for the kernel weights.</p></li>
<li><p><strong>bias_initializer</strong> (<em>str</em>) – The name of the initializer to use for the bias weights.</p></li>
<li><p><strong>kernel_regularizer</strong> (<em>str</em>) – The name of the regularizer to use for the kernel weights.</p></li>
<li><p><strong>bias_regularizer</strong> (<em>str</em>) – The name of the regularizer to use for the bias weights.</p></li>
<li><p><strong>mixed_policy</strong> (<em>tf.keras.mixed_precision.Policy</em>) – The policy to use for mixed-precision training.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the base class constructor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.MLP_ResNet.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.MLP_ResNet.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass of the neural network with residual connections.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>tf.Tensor</em>) – The input tensor to the network.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>tf.Tensor</em> – The output tensor of the network.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.MLP_ResNet.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.MLP_ResNet.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the configuration of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>dict</em> – The configuration of the layer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.MLP_ResNet.get_prunable_weights">
<span class="sig-name descname"><span class="pre">get_prunable_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.MLP_ResNet.get_prunable_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the list of prunable weights of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>list</em> – The list of prunable weights of the layer.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nif.layers.MLP_SimpleShortCut">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nif.layers.</span></span><span class="sig-name descname"><span class="pre">MLP_SimpleShortCut</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.MLP_SimpleShortCut" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">PrunableLayer</span></code></p>
<p>A fully connected layer with a skip connection that adds the input tensor to the output tensor.
Inherits from tf.keras.layers.Layer and tfmot.sparsity.keras.PrunableLayer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>width</strong> (<em>int</em>) – The number of neurons in the layer.</p></li>
<li><p><strong>activation</strong> (<em>str</em>) – The activation function to use for the layer.</p></li>
<li><p><strong>kernel_initializer</strong> – Initializer for the kernel weights matrix.</p></li>
<li><p><strong>bias_initializer</strong> – Initializer for the bias vector.</p></li>
<li><p><strong>kernel_regularizer</strong> – Regularizer function applied to the kernel weights matrix.</p></li>
<li><p><strong>bias_regularizer</strong> – Regularizer function applied to the bias vector.</p></li>
<li><p><strong>mixed_policy</strong> – Floating-point precision to use for computing the layer.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the base class constructor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.MLP_SimpleShortCut.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.MLP_SimpleShortCut.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the fully connected layer with a skip connection to the input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Input tensor to the layer.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the call method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The result of applying the layer to the input tensor with a skip connection added.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.MLP_SimpleShortCut.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.MLP_SimpleShortCut.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the configuration of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A dictionary containing the configuration of the layer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.MLP_SimpleShortCut.get_prunable_weights">
<span class="sig-name descname"><span class="pre">get_prunable_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.MLP_SimpleShortCut.get_prunable_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the weights of the layer that can be pruned.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The weights of the layer that can be pruned.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nif.layers.JacRegLatentLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nif.layers.</span></span><span class="sig-name descname"><span class="pre">JacRegLatentLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.JacRegLatentLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nif.layers.JacobianLayer" title="nif.layers.gradient.JacobianLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">JacobianLayer</span></code></a></p>
<p>A custom Keras layer that applies Jacobian regularization to a TensorFlow model’s output.</p>
<p>This layer computes the Jacobian matrix of the output with respect to the input, and
adds a regularization term to the loss function to encourage the Jacobian to be
small. The regularization term is given by:</p>
<blockquote>
<div><p>L = l1 * mean((df/dx)^2)</p>
</div></blockquote>
<p>where <cite>l1</cite> is a hyperparameter controlling the strength of the regularization,
<cite>f</cite> is the TensorFlow model, <cite>y</cite> is its output, and <cite>x</cite> is its input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – The TensorFlow model for which to compute the Jacobian.</p></li>
<li><p><strong>y_index</strong> (<em>int or List[int]</em>) – The index or indices of the output variable(s) to compute the
Jacobian with respect to.</p></li>
<li><p><strong>x_index</strong> (<em>int or List[int]</em>) – The index or indices of the input variable(s) to compute the
Jacobian with respect to.</p></li>
<li><p><strong>l1</strong> (<em>float</em>) – The weight of the Jacobian regularization term in the loss function.</p></li>
<li><p><strong>mixed_policy</strong> (<em>str</em>) – The floating-point precision to use for computing the Jacobian.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the base class constructor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.JacRegLatentLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.JacRegLatentLayer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the output of the model and the Jacobian regularization loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>tf.Tensor</em>) – The input tensor(s) to the model.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the underlying TensorFlow function.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>tf.Tensor</em> – The output of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.JacRegLatentLayer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.JacRegLatentLayer.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the configuration of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Dict[str, Any]</em> – The configuration of the layer.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nif.layers.JacobianLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nif.layers.</span></span><span class="sig-name descname"><span class="pre">JacobianLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.JacobianLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>A custom Keras layer that computes the Jacobian matrix of a TensorFlow model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – The TensorFlow model for which to compute the Jacobian.</p></li>
<li><p><strong>y_index</strong> (<em>int or List[int]</em>) – The index or indices of the output variable(s) to compute the Jacobian
with respect to.</p></li>
<li><p><strong>x_index</strong> (<em>int or List[int]</em>) – The index or indices of the input variable(s) to compute the Jacobian
with respect to.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple[tf.Tensor, tf.Tensor]</em> – A tuple containing the output of the model and the Jacobian matrix.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.JacobianLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.JacobianLayer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the output of the model and the Jacobian matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>tf.Tensor</em>) – The input tensor(s) to the model.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the underlying TensorFlow function.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple[tf.Tensor, tf.Tensor]</em> – A tuple containing the output of the model and the Jacobian matrix.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nif.layers.HessianLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nif.layers.</span></span><span class="sig-name descname"><span class="pre">HessianLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.HessianLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>A custom Keras layer that computes the Hessian matrix of a TensorFlow model’s output.</p>
<p>This layer computes the Hessian matrix of the output with respect to the input, and
returns it along with the first and second derivatives of the output with respect to
the input. The first derivative is given by the Jacobian matrix, and the second
derivative is the Hessian matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – The TensorFlow model for which to compute the Hessian.</p></li>
<li><p><strong>y_index</strong> (<em>int or List[int]</em>) – The index or indices of the output variable(s) to compute
the Hessian with respect to.</p></li>
<li><p><strong>x_index</strong> (<em>int or List[int]</em>) – The index or indices of the input variable(s) to compute
the Hessian with respect to.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.HessianLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.HessianLayer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the output of the model, the Jacobian matrix, and the Hessian matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>tf.Tensor</em>) – The input tensor(s) to the model.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the underlying TensorFlow function.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><em>Tuple[tf.Tensor, tf.Tensor, tf.Tensor]</em> –</p>
<dl class="simple">
<dt>A tuple containing the output of the model,</dt><dd><p>the Jacobian matrix, and the
Hessian matrix.</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nif.layers.ParameterOutputL1ActReg">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nif.layers.</span></span><span class="sig-name descname"><span class="pre">ParameterOutputL1ActReg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.ParameterOutputL1ActReg" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Custom Keras layer for parameter output L1 activation regularization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – The TensorFlow model whose parameter output activations are to be regularized.</p></li>
<li><p><strong>l1</strong> (<em>float</em>) – The weight of the L1 regularization term in the loss function.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.ParameterOutputL1ActReg.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.ParameterOutputL1ActReg.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the output of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>tf.Tensor</em>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor with parameter output L1 activation regularization applied.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nif.layers.EinsumLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nif.layers.</span></span><span class="sig-name descname"><span class="pre">EinsumLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.EinsumLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>A custom layer that wraps a single tf.einsum operation.</p>
<p>Usage:
x = EinsumLayer(“bmhwf,bmoh-&gt;bmowf”)((x1, x2))</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>equation</strong> (<em>str</em>) – The Einstein summation notation equation to use for the operation.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the base class constructor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.EinsumLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.EinsumLayer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the tf.einsum operation on the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>tuple[tf.Tensor]</em>) – A tuple of input tensors to the operation.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>tf.Tensor</em> – The output tensor of the operation.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.EinsumLayer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.EinsumLayer.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the configuration of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>dict</em> – A dictionary containing the configuration of the layer.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nif.layers.BiasAddLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nif.layers.</span></span><span class="sig-name descname"><span class="pre">BiasAddLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.BiasAddLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>A custom layer that adds a bias vector to the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_dim</strong> (<em>int</em>) – The dimensionality of the output space.</p></li>
<li><p><strong>mixed_policy</strong> (<em>str</em>) – The floating-point precision to use for the bias vector.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the base class constructor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.BiasAddLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.BiasAddLayer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds the bias vector to the input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>tf.Tensor</em>) – The input tensor to add the bias vector to.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>tf.Tensor</em> – The input tensor with the bias vector added to it.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nif.layers.BiasAddLayer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nif.layers.BiasAddLayer.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the configuration of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>dict</em> – A dictionary containing the configuration of the layer.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">nif.layers</a><ul>
<li><a class="reference internal" href="#nif.layers.SIREN"><code class="docutils literal notranslate"><span class="pre">SIREN</span></code></a><ul>
<li><a class="reference internal" href="#nif.layers.SIREN.call"><code class="docutils literal notranslate"><span class="pre">SIREN.call()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.SIREN.get_config"><code class="docutils literal notranslate"><span class="pre">SIREN.get_config()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.SIREN.get_prunable_weights"><code class="docutils literal notranslate"><span class="pre">SIREN.get_prunable_weights()</span></code></a></li>
<li><a class="reference internal" href="#id0"><code class="docutils literal notranslate"><span class="pre">SIREN.call()</span></code></a></li>
<li><a class="reference internal" href="#id1"><code class="docutils literal notranslate"><span class="pre">SIREN.get_config()</span></code></a></li>
<li><a class="reference internal" href="#id2"><code class="docutils literal notranslate"><span class="pre">SIREN.get_prunable_weights()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#nif.layers.SIREN_ResNet"><code class="docutils literal notranslate"><span class="pre">SIREN_ResNet</span></code></a><ul>
<li><a class="reference internal" href="#nif.layers.SIREN_ResNet.call"><code class="docutils literal notranslate"><span class="pre">SIREN_ResNet.call()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.SIREN_ResNet.get_prunable_weights"><code class="docutils literal notranslate"><span class="pre">SIREN_ResNet.get_prunable_weights()</span></code></a></li>
<li><a class="reference internal" href="#id3"><code class="docutils literal notranslate"><span class="pre">SIREN_ResNet.call()</span></code></a></li>
<li><a class="reference internal" href="#id4"><code class="docutils literal notranslate"><span class="pre">SIREN_ResNet.get_prunable_weights()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#nif.layers.Dense"><code class="docutils literal notranslate"><span class="pre">Dense</span></code></a><ul>
<li><a class="reference internal" href="#nif.layers.Dense.build"><code class="docutils literal notranslate"><span class="pre">Dense.build()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.Dense.call"><code class="docutils literal notranslate"><span class="pre">Dense.call()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.Dense.compute_output_shape"><code class="docutils literal notranslate"><span class="pre">Dense.compute_output_shape()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.Dense.get_config"><code class="docutils literal notranslate"><span class="pre">Dense.get_config()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#nif.layers.HyperLinearForSIREN"><code class="docutils literal notranslate"><span class="pre">HyperLinearForSIREN</span></code></a><ul>
<li><a class="reference internal" href="#nif.layers.HyperLinearForSIREN.call"><code class="docutils literal notranslate"><span class="pre">HyperLinearForSIREN.call()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.HyperLinearForSIREN.get_config"><code class="docutils literal notranslate"><span class="pre">HyperLinearForSIREN.get_config()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.HyperLinearForSIREN.get_prunable_weights"><code class="docutils literal notranslate"><span class="pre">HyperLinearForSIREN.get_prunable_weights()</span></code></a></li>
<li><a class="reference internal" href="#id5"><code class="docutils literal notranslate"><span class="pre">HyperLinearForSIREN.call()</span></code></a></li>
<li><a class="reference internal" href="#id6"><code class="docutils literal notranslate"><span class="pre">HyperLinearForSIREN.get_config()</span></code></a></li>
<li><a class="reference internal" href="#id7"><code class="docutils literal notranslate"><span class="pre">HyperLinearForSIREN.get_prunable_weights()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#nif.layers.MLP_ResNet"><code class="docutils literal notranslate"><span class="pre">MLP_ResNet</span></code></a><ul>
<li><a class="reference internal" href="#nif.layers.MLP_ResNet.call"><code class="docutils literal notranslate"><span class="pre">MLP_ResNet.call()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.MLP_ResNet.get_config"><code class="docutils literal notranslate"><span class="pre">MLP_ResNet.get_config()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.MLP_ResNet.get_prunable_weights"><code class="docutils literal notranslate"><span class="pre">MLP_ResNet.get_prunable_weights()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#nif.layers.MLP_SimpleShortCut"><code class="docutils literal notranslate"><span class="pre">MLP_SimpleShortCut</span></code></a><ul>
<li><a class="reference internal" href="#nif.layers.MLP_SimpleShortCut.call"><code class="docutils literal notranslate"><span class="pre">MLP_SimpleShortCut.call()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.MLP_SimpleShortCut.get_config"><code class="docutils literal notranslate"><span class="pre">MLP_SimpleShortCut.get_config()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.MLP_SimpleShortCut.get_prunable_weights"><code class="docutils literal notranslate"><span class="pre">MLP_SimpleShortCut.get_prunable_weights()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#nif.layers.JacRegLatentLayer"><code class="docutils literal notranslate"><span class="pre">JacRegLatentLayer</span></code></a><ul>
<li><a class="reference internal" href="#nif.layers.JacRegLatentLayer.call"><code class="docutils literal notranslate"><span class="pre">JacRegLatentLayer.call()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.JacRegLatentLayer.get_config"><code class="docutils literal notranslate"><span class="pre">JacRegLatentLayer.get_config()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#nif.layers.JacobianLayer"><code class="docutils literal notranslate"><span class="pre">JacobianLayer</span></code></a><ul>
<li><a class="reference internal" href="#nif.layers.JacobianLayer.call"><code class="docutils literal notranslate"><span class="pre">JacobianLayer.call()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#nif.layers.HessianLayer"><code class="docutils literal notranslate"><span class="pre">HessianLayer</span></code></a><ul>
<li><a class="reference internal" href="#nif.layers.HessianLayer.call"><code class="docutils literal notranslate"><span class="pre">HessianLayer.call()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#nif.layers.ParameterOutputL1ActReg"><code class="docutils literal notranslate"><span class="pre">ParameterOutputL1ActReg</span></code></a><ul>
<li><a class="reference internal" href="#nif.layers.ParameterOutputL1ActReg.call"><code class="docutils literal notranslate"><span class="pre">ParameterOutputL1ActReg.call()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#nif.layers.EinsumLayer"><code class="docutils literal notranslate"><span class="pre">EinsumLayer</span></code></a><ul>
<li><a class="reference internal" href="#nif.layers.EinsumLayer.call"><code class="docutils literal notranslate"><span class="pre">EinsumLayer.call()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.EinsumLayer.get_config"><code class="docutils literal notranslate"><span class="pre">EinsumLayer.get_config()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#nif.layers.BiasAddLayer"><code class="docutils literal notranslate"><span class="pre">BiasAddLayer</span></code></a><ul>
<li><a class="reference internal" href="#nif.layers.BiasAddLayer.call"><code class="docutils literal notranslate"><span class="pre">BiasAddLayer.call()</span></code></a></li>
<li><a class="reference internal" href="#nif.layers.BiasAddLayer.get_config"><code class="docutils literal notranslate"><span class="pre">BiasAddLayer.get_config()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/api_nif_layers.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="api_nif_model.html" title="nif.model"
             >next</a> |</li>
        <li class="right" >
          <a href="api_nif_optimizers.html" title="nif.optimizers"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">NIF  documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">nif.layers</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright .
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 6.1.3.
    </div>
  </body>
</html>